{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1: выполнил Шиширин В.Н. М8О-310Б-23\n",
    "\n",
    "## План работы\n",
    "1. Анализ данных\n",
    "2. Создание признаков\n",
    "3. Обучение модели\n",
    "4. Оценка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (11017, 35)\n",
      "Test shape: (5000, 35)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация методов нормализации\n",
    "\n",
    "Реализуем z-score и min-max нормализацию вручную и сравниваем с sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение z-score:\n",
      "Моя реализация:\n",
      "[[-1.34164079 -1.34164079]\n",
      " [-0.4472136  -0.4472136 ]\n",
      " [ 0.4472136   0.4472136 ]\n",
      " [ 1.34164079  1.34164079]]\n",
      "Sklearn:\n",
      "[[-1.34164079 -1.34164079]\n",
      " [-0.4472136  -0.4472136 ]\n",
      " [ 0.4472136   0.4472136 ]\n",
      " [ 1.34164079  1.34164079]]\n",
      "Разница: 0.0000000000\n",
      "\n",
      "Сравнение min-max:\n",
      "Моя реализация:\n",
      "[[0.         0.        ]\n",
      " [0.33333333 0.33333333]\n",
      " [0.66666667 0.66666667]\n",
      " [1.         1.        ]]\n",
      "Sklearn:\n",
      "[[0.         0.        ]\n",
      " [0.33333333 0.33333333]\n",
      " [0.66666667 0.66666667]\n",
      " [1.         1.        ]]\n",
      "Разница: 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "# Реализация z-score нормализации\n",
    "def z_score_normalization(X):\n",
    "    \"\"\"Нормализация z-score вручную\"\"\"\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    # Чтобы не делить на 0\n",
    "    std[std == 0] = 1\n",
    "    return (X - mean) / std, mean, std\n",
    "\n",
    "# Реализация min-max нормализации\n",
    "def min_max_normalization(X):\n",
    "    \"\"\"Нормализация min-max вручную\"\"\"\n",
    "    min_val = np.min(X, axis=0)\n",
    "    max_val = np.max(X, axis=0)\n",
    "    # Чтобы не делить на 0\n",
    "    range_val = max_val - min_val\n",
    "    range_val[range_val == 0] = 1\n",
    "    return (X - min_val) / range_val, min_val, max_val\n",
    "\n",
    "# Тестируем на небольшом примере\n",
    "test_data = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "\n",
    "# Моя z-score\n",
    "my_zscore, _, _ = z_score_normalization(test_data)\n",
    "\n",
    "# sklearn z-score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sklearn_scaler = StandardScaler()\n",
    "sklearn_zscore = sklearn_scaler.fit_transform(test_data)\n",
    "\n",
    "# Моя min-max\n",
    "my_minmax, _, _ = min_max_normalization(test_data)\n",
    "\n",
    "# sklearn min-max\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sklearn_mm = MinMaxScaler()\n",
    "sklearn_minmax = sklearn_mm.fit_transform(test_data)\n",
    "\n",
    "print(\"Сравнение z-score:\")\n",
    "print(f\"Моя реализация:\\n{my_zscore}\")\n",
    "print(f\"Sklearn:\\n{sklearn_zscore}\")\n",
    "print(f\"Разница: {np.abs(my_zscore - sklearn_zscore).max():.10f}\")\n",
    "\n",
    "print(\"\\nСравнение min-max:\")\n",
    "print(f\"Моя реализация:\\n{my_minmax}\")\n",
    "print(f\"Sklearn:\\n{sklearn_minmax}\")\n",
    "print(f\"Разница: {np.abs(my_minmax - sklearn_minmax).max():.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация метрик качества\n",
    "\n",
    "Реализуем MSE, MAE, R² и MAPE вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение метрик на тестовых данных:\n",
      "\n",
      "MSE:\n",
      "  Моя: 0.3750000000\n",
      "  Sklearn: 0.3750000000\n",
      "\n",
      "MAE:\n",
      "  Моя: 0.5000000000\n",
      "  Sklearn: 0.5000000000\n",
      "\n",
      "R²:\n",
      "  Моя: 0.9486081370\n",
      "  Sklearn: 0.9486081370\n",
      "\n",
      "MAPE:\n",
      "  Моя: 32.7380952381%\n"
     ]
    }
   ],
   "source": [
    "# Реализация MSE\n",
    "def my_mse(y_true, y_pred):\n",
    "    \"\"\"Mean Squared Error\"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Реализация MAE\n",
    "def my_mae(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Error\"\"\"\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "# Реализация R²\n",
    "def my_r2(y_true, y_pred):\n",
    "    \"\"\"R-squared (коэффициент детерминации)\"\"\"\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Реализация MAPE\n",
    "def my_mape(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Percentage Error\"\"\"\n",
    "    # Избегаем деления на 0\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "# Тестируем метрики\n",
    "y_true_test = np.array([3, -0.5, 2, 7])\n",
    "y_pred_test = np.array([2.5, 0.0, 2, 8])\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "print(\"Сравнение метрик на тестовых данных:\")\n",
    "print(\"\\nMSE:\")\n",
    "print(f\"  Моя: {my_mse(y_true_test, y_pred_test):.10f}\")\n",
    "print(f\"  Sklearn: {mean_squared_error(y_true_test, y_pred_test):.10f}\")\n",
    "\n",
    "print(\"\\nMAE:\")\n",
    "print(f\"  Моя: {my_mae(y_true_test, y_pred_test):.10f}\")\n",
    "print(f\"  Sklearn: {mean_absolute_error(y_true_test, y_pred_test):.10f}\")\n",
    "\n",
    "print(\"\\nR²:\")\n",
    "print(f\"  Моя: {my_r2(y_true_test, y_pred_test):.10f}\")\n",
    "print(f\"  Sklearn: {r2_score(y_true_test, y_pred_test):.10f}\")\n",
    "\n",
    "print(\"\\nMAPE:\")\n",
    "print(f\"  Моя: {my_mape(y_true_test, y_pred_test):.10f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация класса линейной регрессии\n",
    "\n",
    "Реализуем линейную регрессию через аналитическую формулу, градиентный спуск и стохастический градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение методов на синтетических данных:\n",
      "\n",
      "Аналитическое решение:\n",
      "  MSE: 0.189191\n",
      "  Веса: [ 2.96116836  1.97501822 -1.05379666]\n",
      "  Bias: 5.056431\n",
      "\n",
      "Градиентный спуск:\n",
      "  MSE: 0.189191\n",
      "  Веса: [ 2.96116836  1.97501822 -1.05379666]\n",
      "  Bias: 5.056431\n",
      "\n",
      "Стохастический градиентный спуск:\n",
      "  MSE: 0.194333\n",
      "  Веса: [ 2.97439016  1.95190473 -1.11456951]\n",
      "  Bias: 5.068314\n",
      "\n",
      "Sklearn LinearRegression:\n",
      "  MSE: 0.189191\n",
      "  Веса: [ 2.96116836  1.97501822 -1.05379666]\n",
      "  Bias: 5.056431\n"
     ]
    }
   ],
   "source": [
    "class MyLinearRegression:\n",
    "    \"\"\"Линейная регрессия с несколькими методами обучения\"\"\"\n",
    "    \n",
    "    def __init__(self, method='normal', learning_rate=0.01, n_iterations=1000, batch_size=32):\n",
    "        \"\"\"\n",
    "        method: 'normal' - аналитическое решение\n",
    "                'gd' - градиентный спуск\n",
    "                'sgd' - стохастический градиентный спуск\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.batch_size = batch_size\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение модели\"\"\"\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        if self.method == 'normal':\n",
    "            # Аналитическое решение: w = (X^T X)^(-1) X^T y\n",
    "            X_b = np.c_[np.ones((n_samples, 1)), X]  # добавляем столбец единиц для bias\n",
    "            theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "            self.bias = theta[0]\n",
    "            self.weights = theta[1:]\n",
    "            \n",
    "        elif self.method == 'gd':\n",
    "            # Градиентный спуск\n",
    "            self.weights = np.zeros(n_features)\n",
    "            self.bias = 0\n",
    "            \n",
    "            for _ in range(self.n_iterations):\n",
    "                y_pred = self.predict(X)\n",
    "                \n",
    "                # Вычисляем градиенты\n",
    "                dw = -(2/n_samples) * X.T.dot(y - y_pred)\n",
    "                db = -(2/n_samples) * np.sum(y - y_pred)\n",
    "                \n",
    "                # Обновляем веса\n",
    "                self.weights -= self.learning_rate * dw\n",
    "                self.bias -= self.learning_rate * db\n",
    "                \n",
    "        elif self.method == 'sgd':\n",
    "            # Стохастический градиентный спуск\n",
    "            self.weights = np.zeros(n_features)\n",
    "            self.bias = 0\n",
    "            \n",
    "            for _ in range(self.n_iterations):\n",
    "                # Перемешиваем данные\n",
    "                indices = np.random.permutation(n_samples)\n",
    "                X_shuffled = X[indices]\n",
    "                y_shuffled = y[indices]\n",
    "                \n",
    "                # Проходим по мини-батчам\n",
    "                for i in range(0, n_samples, self.batch_size):\n",
    "                    X_batch = X_shuffled[i:i+self.batch_size]\n",
    "                    y_batch = y_shuffled[i:i+self.batch_size]\n",
    "                    \n",
    "                    y_pred = self.predict(X_batch)\n",
    "                    batch_size = len(X_batch)\n",
    "                    \n",
    "                    # Градиенты\n",
    "                    dw = -(2/batch_size) * X_batch.T.dot(y_batch - y_pred)\n",
    "                    db = -(2/batch_size) * np.sum(y_batch - y_pred)\n",
    "                    \n",
    "                    # Обновляем веса\n",
    "                    self.weights -= self.learning_rate * dw\n",
    "                    self.bias -= self.learning_rate * db\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание\"\"\"\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "# Тестируем на простых данных\n",
    "np.random.seed(42)\n",
    "X_simple = np.random.randn(100, 3)\n",
    "y_simple = 3*X_simple[:, 0] + 2*X_simple[:, 1] - X_simple[:, 2] + 5 + np.random.randn(100)*0.5\n",
    "\n",
    "print(\"Сравнение методов на синтетических данных:\\n\")\n",
    "\n",
    "# Аналитическое решение\n",
    "model_normal = MyLinearRegression(method='normal')\n",
    "model_normal.fit(X_simple, y_simple)\n",
    "y_pred_normal = model_normal.predict(X_simple)\n",
    "print(f\"Аналитическое решение:\")\n",
    "print(f\"  MSE: {my_mse(y_simple, y_pred_normal):.6f}\")\n",
    "print(f\"  Веса: {model_normal.weights}\")\n",
    "print(f\"  Bias: {model_normal.bias:.6f}\")\n",
    "\n",
    "# Градиентный спуск\n",
    "model_gd = MyLinearRegression(method='gd', learning_rate=0.1, n_iterations=1000)\n",
    "model_gd.fit(X_simple, y_simple)\n",
    "y_pred_gd = model_gd.predict(X_simple)\n",
    "print(f\"\\nГрадиентный спуск:\")\n",
    "print(f\"  MSE: {my_mse(y_simple, y_pred_gd):.6f}\")\n",
    "print(f\"  Веса: {model_gd.weights}\")\n",
    "print(f\"  Bias: {model_gd.bias:.6f}\")\n",
    "\n",
    "# Стохастический градиентный спуск\n",
    "model_sgd = MyLinearRegression(method='sgd', learning_rate=0.1, n_iterations=100, batch_size=16)\n",
    "model_sgd.fit(X_simple, y_simple)\n",
    "y_pred_sgd = model_sgd.predict(X_simple)\n",
    "print(f\"\\nСтохастический градиентный спуск:\")\n",
    "print(f\"  MSE: {my_mse(y_simple, y_pred_sgd):.6f}\")\n",
    "print(f\"  Веса: {model_sgd.weights}\")\n",
    "print(f\"  Bias: {model_sgd.bias:.6f}\")\n",
    "\n",
    "# Sklearn для сравнения\n",
    "from sklearn.linear_model import LinearRegression\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.fit(X_simple, y_simple)\n",
    "y_pred_sklearn = sklearn_model.predict(X_simple)\n",
    "print(f\"\\nSklearn LinearRegression:\")\n",
    "print(f\"  MSE: {my_mse(y_simple, y_pred_sklearn):.6f}\")\n",
    "print(f\"  Веса: {sklearn_model.coef_}\")\n",
    "print(f\"  Bias: {sklearn_model.intercept_:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация кросс-валидации\n",
    "\n",
    "Реализуем k-fold и leave-one-out кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование кросс-валидации:\n",
      "\n",
      "Моя K-Fold (k=5):\n",
      "  Scores: [0.1757781  0.17181217 0.11833156 0.13926956 0.20927438]\n",
      "  Mean MSE: 0.162893 (+/- 0.031434)\n",
      "\n",
      "Sklearn K-Fold (k=5):\n",
      "  Mean MSE: 0.167374 (+/- 0.049017)\n",
      "\n",
      "Моя Leave-One-Out (n=20):\n",
      "  Mean MSE: 0.147139 (+/- 0.143904)\n",
      "\n",
      "Sklearn Leave-One-Out (n=20):\n",
      "  Mean MSE: 0.147139 (+/- 0.143904)\n"
     ]
    }
   ],
   "source": [
    "def my_kfold_cv(X, y, model, k=5, metric_fn=my_mse):\n",
    "    \"\"\"K-Fold кросс-валидация\"\"\"\n",
    "    n_samples = len(X)\n",
    "    fold_size = n_samples // k\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Разделяем на train и validation\n",
    "        val_start = i * fold_size\n",
    "        val_end = (i + 1) * fold_size if i < k - 1 else n_samples\n",
    "        \n",
    "        val_indices = indices[val_start:val_end]\n",
    "        train_indices = np.concatenate([indices[:val_start], indices[val_end:]])\n",
    "        \n",
    "        X_train_fold = X[train_indices]\n",
    "        y_train_fold = y[train_indices]\n",
    "        X_val_fold = X[val_indices]\n",
    "        y_val_fold = y[val_indices]\n",
    "        \n",
    "        # Обучаем и предсказываем\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        # Считаем метрику\n",
    "        score = metric_fn(y_val_fold, y_pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.array(scores)\n",
    "\n",
    "def my_loocv(X, y, model, metric_fn=my_mse):\n",
    "    \"\"\"Leave-One-Out кросс-валидация\"\"\"\n",
    "    n_samples = len(X)\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Убираем один элемент для валидации\n",
    "        X_train = np.delete(X, i, axis=0)\n",
    "        y_train = np.delete(y, i)\n",
    "        X_val = X[i:i+1]\n",
    "        y_val = y[i:i+1]\n",
    "        \n",
    "        # Обучаем и предсказываем\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # Считаем метрику\n",
    "        score = metric_fn(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return np.array(scores)\n",
    "\n",
    "# Тестируем на небольшом датасете\n",
    "X_cv_test = X_simple[:50]\n",
    "y_cv_test = y_simple[:50]\n",
    "\n",
    "print(\"Тестирование кросс-валидации:\\n\")\n",
    "\n",
    "# K-Fold с нашей реализацией\n",
    "model_test = MyLinearRegression(method='normal')\n",
    "my_kfold_scores = my_kfold_cv(X_cv_test, y_cv_test, model_test, k=5)\n",
    "print(f\"Моя K-Fold (k=5):\")\n",
    "print(f\"  Scores: {my_kfold_scores}\")\n",
    "print(f\"  Mean MSE: {my_kfold_scores.mean():.6f} (+/- {my_kfold_scores.std():.6f})\")\n",
    "\n",
    "# K-Fold sklearn для сравнения\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "sklearn_kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "sklearn_scores = -cross_val_score(LinearRegression(), X_cv_test, y_cv_test, \n",
    "                                  cv=sklearn_kf, scoring='neg_mean_squared_error')\n",
    "print(f\"\\nSklearn K-Fold (k=5):\")\n",
    "print(f\"  Mean MSE: {sklearn_scores.mean():.6f} (+/- {sklearn_scores.std():.6f})\")\n",
    "\n",
    "# Leave-One-Out на очень маленьком датасете (иначе долго)\n",
    "X_loo_test = X_simple[:20]\n",
    "y_loo_test = y_simple[:20]\n",
    "model_loo = MyLinearRegression(method='normal')\n",
    "my_loo_scores = my_loocv(X_loo_test, y_loo_test, model_loo)\n",
    "print(f\"\\nМоя Leave-One-Out (n=20):\")\n",
    "print(f\"  Mean MSE: {my_loo_scores.mean():.6f} (+/- {my_loo_scores.std():.6f})\")\n",
    "\n",
    "# Sklearn LOO\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "sklearn_loo = LeaveOneOut()\n",
    "sklearn_loo_scores = -cross_val_score(LinearRegression(), X_loo_test, y_loo_test, \n",
    "                                      cv=sklearn_loo, scoring='neg_mean_squared_error')\n",
    "print(f\"\\nSklearn Leave-One-Out (n=20):\")\n",
    "print(f\"  Mean MSE: {sklearn_loo_scores.mean():.6f} (+/- {sklearn_loo_scores.std():.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация линейной регрессии с регуляризацией\n",
    "\n",
    "Реализуем L1 (Lasso), L2 (Ridge), L1+L2 (ElasticNet) и Lp регуляризацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение моделей с регуляризацией:\n",
      "\n",
      "Без регуляризации:\n",
      "  MSE: 0.229981\n",
      "  L2 norm весов: 3.563932\n",
      "\n",
      "L2 (Ridge, alpha=1.0):\n",
      "  MSE: 1.810531\n",
      "  L2 norm весов: 1.495542\n",
      "\n",
      "L1 (Lasso, alpha=0.1):\n",
      "  MSE: 0.241664\n",
      "  Ненулевых весов: 3/5\n",
      "  Веса: [1.90281899e+00 1.89932716e+00 1.43295611e-03 1.02272731e+00\n",
      " 7.58939325e-03]\n",
      "\n",
      "ElasticNet (alpha=0.5, l1_ratio=0.5):\n",
      "  MSE: 0.648156\n",
      "  Ненулевых весов: 4/5\n",
      "\n",
      "Lp (p=1.5, alpha=0.5):\n",
      "  MSE: 0.641303\n",
      "  Lp norm весов: 3.992140\n",
      "\n",
      "Sklearn Ridge (alpha=1.0):\n",
      "  MSE: 0.243942\n",
      "  L2 norm весов: 2.642942\n"
     ]
    }
   ],
   "source": [
    "class MyRegularizedLinearRegression:\n",
    "    \"\"\"Линейная регрессия с регуляризацией L1, L2, L1+L2 и Lp\"\"\"\n",
    "    \n",
    "    def __init__(self, reg_type='l2', alpha=1.0, l1_ratio=0.5, p=2, \n",
    "                 learning_rate=0.01, n_iterations=1000):\n",
    "        \"\"\"\n",
    "        reg_type: 'l1' (Lasso), 'l2' (Ridge), 'elastic' (L1+L2), 'lp'\n",
    "        alpha: коэффициент регуляризации\n",
    "        l1_ratio: соотношение L1 в ElasticNet (0 - чистый L2, 1 - чистый L1)\n",
    "        p: степень для Lp регуляризации\n",
    "        \"\"\"\n",
    "        self.reg_type = reg_type\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.p = p\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение через градиентный спуск\"\"\"\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            # Предсказания\n",
    "            y_pred = self.predict(X)\n",
    "            \n",
    "            # Базовые градиенты\n",
    "            dw = -(2/n_samples) * X.T.dot(y - y_pred)\n",
    "            db = -(2/n_samples) * np.sum(y - y_pred)\n",
    "            \n",
    "            # Добавляем регуляризацию\n",
    "            if self.reg_type == 'l2':\n",
    "                # L2: добавляем 2 * alpha * w\n",
    "                dw += 2 * self.alpha * self.weights\n",
    "                \n",
    "            elif self.reg_type == 'l1':\n",
    "                # L1: добавляем alpha * sign(w)\n",
    "                dw += self.alpha * np.sign(self.weights)\n",
    "                \n",
    "            elif self.reg_type == 'elastic':\n",
    "                # ElasticNet: L1 + L2\n",
    "                l1_term = self.alpha * self.l1_ratio * np.sign(self.weights)\n",
    "                l2_term = self.alpha * (1 - self.l1_ratio) * 2 * self.weights\n",
    "                dw += l1_term + l2_term\n",
    "                \n",
    "            elif self.reg_type == 'lp':\n",
    "                # Lp регуляризация: alpha * p * |w|^(p-1) * sign(w)\n",
    "                # Для избежания деления на 0\n",
    "                w_abs = np.abs(self.weights) + 1e-8\n",
    "                lp_grad = self.alpha * self.p * np.power(w_abs, self.p - 1) * np.sign(self.weights)\n",
    "                dw += lp_grad\n",
    "            \n",
    "            # Обновляем веса\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание\"\"\"\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "\n",
    "# Тестируем регуляризацию на данных с мультиколлинеарностью\n",
    "np.random.seed(42)\n",
    "X_reg = np.random.randn(100, 5)\n",
    "# Добавляем коррелирующие признаки\n",
    "X_reg[:, 3] = X_reg[:, 0] + np.random.randn(100) * 0.1\n",
    "X_reg[:, 4] = X_reg[:, 1] + np.random.randn(100) * 0.1\n",
    "y_reg = 3*X_reg[:, 0] + 2*X_reg[:, 1] + np.random.randn(100)*0.5\n",
    "\n",
    "print(\"Сравнение моделей с регуляризацией:\\n\")\n",
    "\n",
    "# Без регуляризации\n",
    "model_no_reg = MyLinearRegression(method='normal')\n",
    "model_no_reg.fit(X_reg, y_reg)\n",
    "y_pred_no_reg = model_no_reg.predict(X_reg)\n",
    "print(f\"Без регуляризации:\")\n",
    "print(f\"  MSE: {my_mse(y_reg, y_pred_no_reg):.6f}\")\n",
    "print(f\"  L2 norm весов: {np.linalg.norm(model_no_reg.weights):.6f}\")\n",
    "\n",
    "# L2 (Ridge)\n",
    "model_l2 = MyRegularizedLinearRegression(reg_type='l2', alpha=1.0, learning_rate=0.1, n_iterations=1000)\n",
    "model_l2.fit(X_reg, y_reg)\n",
    "y_pred_l2 = model_l2.predict(X_reg)\n",
    "print(f\"\\nL2 (Ridge, alpha=1.0):\")\n",
    "print(f\"  MSE: {my_mse(y_reg, y_pred_l2):.6f}\")\n",
    "print(f\"  L2 norm весов: {np.linalg.norm(model_l2.weights):.6f}\")\n",
    "\n",
    "# L1 (Lasso)\n",
    "model_l1 = MyRegularizedLinearRegression(reg_type='l1', alpha=0.1, learning_rate=0.1, n_iterations=1000)\n",
    "model_l1.fit(X_reg, y_reg)\n",
    "y_pred_l1 = model_l1.predict(X_reg)\n",
    "print(f\"\\nL1 (Lasso, alpha=0.1):\")\n",
    "print(f\"  MSE: {my_mse(y_reg, y_pred_l1):.6f}\")\n",
    "print(f\"  Ненулевых весов: {np.sum(np.abs(model_l1.weights) > 0.01)}/{len(model_l1.weights)}\")\n",
    "print(f\"  Веса: {model_l1.weights}\")\n",
    "\n",
    "# ElasticNet (L1 + L2)\n",
    "model_elastic = MyRegularizedLinearRegression(reg_type='elastic', alpha=0.5, l1_ratio=0.5, \n",
    "                                              learning_rate=0.1, n_iterations=1000)\n",
    "model_elastic.fit(X_reg, y_reg)\n",
    "y_pred_elastic = model_elastic.predict(X_reg)\n",
    "print(f\"\\nElasticNet (alpha=0.5, l1_ratio=0.5):\")\n",
    "print(f\"  MSE: {my_mse(y_reg, y_pred_elastic):.6f}\")\n",
    "print(f\"  Ненулевых весов: {np.sum(np.abs(model_elastic.weights) > 0.01)}/{len(model_elastic.weights)}\")\n",
    "\n",
    "# Lp регуляризация с p=1.5\n",
    "model_lp = MyRegularizedLinearRegression(reg_type='lp', alpha=0.5, p=1.5, \n",
    "                                         learning_rate=0.1, n_iterations=1000)\n",
    "model_lp.fit(X_reg, y_reg)\n",
    "y_pred_lp = model_lp.predict(X_reg)\n",
    "print(f\"\\nLp (p=1.5, alpha=0.5):\")\n",
    "print(f\"  MSE: {my_mse(y_reg, y_pred_lp):.6f}\")\n",
    "print(f\"  Lp norm весов: {np.sum(np.abs(model_lp.weights)**1.5):.6f}\")\n",
    "\n",
    "# Сравнение со sklearn\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet as SklearnElasticNet\n",
    "\n",
    "sklearn_ridge = Ridge(alpha=1.0)\n",
    "sklearn_ridge.fit(X_reg, y_reg)\n",
    "print(f\"\\nSklearn Ridge (alpha=1.0):\")\n",
    "print(f\"  MSE: {my_mse(y_reg, sklearn_ridge.predict(X_reg)):.6f}\")\n",
    "print(f\"  L2 norm весов: {np.linalg.norm(sklearn_ridge.coef_):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сводка реализованных заданий\n",
    "\n",
    "Проверка всех реализованных методов на учебном примере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Учебный датасет: 140 train, 60 test samples\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. НОРМАЛИЗАЦИЯ\n",
      "--------------------------------------------------------------------------------\n",
      " Z-score нормализация реализована\n",
      " Min-max нормализация реализована\n",
      "\n",
      "2. МЕТРИКИ\n",
      "--------------------------------------------------------------------------------\n",
      " MSE реализована:  0.6003\n",
      " MAE реализована:  0.6034\n",
      " R² реализована:   0.9498\n",
      " MAPE реализована: 5.9763%\n",
      "\n",
      "3. КЛАСС ЛИНЕЙНОЙ РЕГРЕССИИ\n",
      "--------------------------------------------------------------------------------\n",
      " Аналитическая формула     MSE: 0.6003\n",
      " Градиентный спуск         MSE: 0.6003\n",
      " Стохастический ГС         MSE: 0.6456\n",
      "  Sklearn LinearRegression:     MSE: 0.6003\n",
      "\n",
      "4. КРОСС-ВАЛИДАЦИЯ\n",
      "--------------------------------------------------------------------------------\n",
      " K-Fold (k=5):       MSE = 0.6239 (+/- 0.1359)\n",
      " Leave-One-Out (n=30): MSE = 0.5188 (+/- 0.5082)\n",
      "\n",
      "5. РЕГУЛЯРИЗАЦИЯ\n",
      "--------------------------------------------------------------------------------\n",
      " L2 (Ridge)                MSE: 4.0742\n",
      " L1 (Lasso)                MSE: 0.6115\n",
      " L1+L2 (ElasticNet)        MSE: 1.5076\n",
      " Lp (p=1.5)                MSE: 1.3610\n"
     ]
    }
   ],
   "source": [
    "# Создаем учебный датасет\n",
    "np.random.seed(123)\n",
    "X_demo = np.random.randn(200, 4)\n",
    "y_demo = 2*X_demo[:, 0] + 3*X_demo[:, 1] - X_demo[:, 2] + 0.5*X_demo[:, 3] + 10 + np.random.randn(200)*0.8\n",
    "\n",
    "X_train_demo, X_test_demo, y_train_demo, y_test_demo = train_test_split(\n",
    "    X_demo, y_demo, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nУчебный датасет: {X_train_demo.shape[0]} train, {X_test_demo.shape[0]} test samples\")\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "\n",
    "# 1. Нормализация\n",
    "print(\"\\n1. НОРМАЛИЗАЦИЯ\")\n",
    "print(\"-\"*80)\n",
    "X_zscore, _, _ = z_score_normalization(X_train_demo)\n",
    "X_minmax, _, _ = min_max_normalization(X_train_demo)\n",
    "print(\" Z-score нормализация реализована\")\n",
    "print(\" Min-max нормализация реализована\")\n",
    "\n",
    "# 2. Метрики\n",
    "print(\"\\n2. МЕТРИКИ\")\n",
    "print(\"-\"*80)\n",
    "model_metrics = MyLinearRegression(method='normal')\n",
    "model_metrics.fit(X_train_demo, y_train_demo)\n",
    "y_pred_metrics = model_metrics.predict(X_test_demo)\n",
    "\n",
    "print(f\" MSE реализована:  {my_mse(y_test_demo, y_pred_metrics):.4f}\")\n",
    "print(f\" MAE реализована:  {my_mae(y_test_demo, y_pred_metrics):.4f}\")\n",
    "print(f\" R² реализована:   {my_r2(y_test_demo, y_pred_metrics):.4f}\")\n",
    "print(f\" MAPE реализована: {my_mape(y_test_demo, y_pred_metrics):.4f}%\")\n",
    "\n",
    "# 3. Линейная регрессия\n",
    "print(\"\\n3. КЛАСС ЛИНЕЙНОЙ РЕГРЕССИИ\")\n",
    "print(\"-\"*80)\n",
    "methods = ['normal', 'gd', 'sgd']\n",
    "for method in methods:\n",
    "    if method == 'sgd':\n",
    "        model_lr = MyLinearRegression(method=method, learning_rate=0.1, n_iterations=100)\n",
    "    else:\n",
    "        model_lr = MyLinearRegression(method=method, learning_rate=0.1, n_iterations=1000)\n",
    "    model_lr.fit(X_train_demo, y_train_demo)\n",
    "    y_pred_lr = model_lr.predict(X_test_demo)\n",
    "    mse = my_mse(y_test_demo, y_pred_lr)\n",
    "    \n",
    "    method_names = {'normal': 'Аналитическая формула', 'gd': 'Градиентный спуск', 'sgd': 'Стохастический ГС'}\n",
    "    print(f\" {method_names[method]:25s} MSE: {mse:.4f}\")\n",
    "\n",
    "# Сравнение с sklearn\n",
    "sklearn_lr = LinearRegression()\n",
    "sklearn_lr.fit(X_train_demo, y_train_demo)\n",
    "y_pred_sklearn = sklearn_lr.predict(X_test_demo)\n",
    "print(f\"  Sklearn LinearRegression:     MSE: {my_mse(y_test_demo, y_pred_sklearn):.4f}\")\n",
    "\n",
    "# 4. Кросс-валидация\n",
    "print(\"\\n4. КРОСС-ВАЛИДАЦИЯ\")\n",
    "print(\"-\"*80)\n",
    "model_cv = MyLinearRegression(method='normal')\n",
    "kfold_scores = my_kfold_cv(X_train_demo, y_train_demo, model_cv, k=5)\n",
    "print(f\" K-Fold (k=5):       MSE = {kfold_scores.mean():.4f} (+/- {kfold_scores.std():.4f})\")\n",
    "\n",
    "# LOO на небольшой выборке\n",
    "X_loo_demo = X_train_demo[:30]\n",
    "y_loo_demo = y_train_demo[:30]\n",
    "loo_scores = my_loocv(X_loo_demo, y_loo_demo, model_cv)\n",
    "print(f\" Leave-One-Out (n=30): MSE = {loo_scores.mean():.4f} (+/- {loo_scores.std():.4f})\")\n",
    "\n",
    "# 5. Регуляризация\n",
    "print(\"\\n5. РЕГУЛЯРИЗАЦИЯ\")\n",
    "print(\"-\"*80)\n",
    "reg_models = [\n",
    "    ('L2 (Ridge)', 'l2', 1.0, None),\n",
    "    ('L1 (Lasso)', 'l1', 0.1, None),\n",
    "    ('L1+L2 (ElasticNet)', 'elastic', 0.5, 0.5),\n",
    "    ('Lp (p=1.5)', 'lp', 0.5, 1.5)\n",
    "]\n",
    "\n",
    "for name, reg_type, alpha, param in reg_models:\n",
    "    if reg_type == 'elastic':\n",
    "        model_reg = MyRegularizedLinearRegression(reg_type=reg_type, alpha=alpha, l1_ratio=param,\n",
    "                                                  learning_rate=0.1, n_iterations=1000)\n",
    "    elif reg_type == 'lp':\n",
    "        model_reg = MyRegularizedLinearRegression(reg_type=reg_type, alpha=alpha, p=param,\n",
    "                                                  learning_rate=0.1, n_iterations=1000)\n",
    "    else:\n",
    "        model_reg = MyRegularizedLinearRegression(reg_type=reg_type, alpha=alpha,\n",
    "                                                  learning_rate=0.1, n_iterations=1000)\n",
    "    \n",
    "    model_reg.fit(X_train_demo, y_train_demo)\n",
    "    y_pred_reg = model_reg.predict(X_test_demo)\n",
    "    mse = my_mse(y_test_demo, y_pred_reg)\n",
    "    print(f\" {name:25s} MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропущенные значения:\n",
      "MonthlyDebtPayments           1031\n",
      "LoanAmount                    1031\n",
      "CreditScore                   1031\n",
      "BaseInterestRate              1031\n",
      "NetWorth                      1031\n",
      "TotalAssets                   1031\n",
      "BankruptcyHistory             1031\n",
      "LoanPurpose                   1031\n",
      "CheckingAccountBalance        1031\n",
      "ApplicationDate                530\n",
      "Age                            530\n",
      "AnnualIncome                   530\n",
      "HomeOwnershipStatus            530\n",
      "NumberOfCreditInquiries        530\n",
      "NumberOfOpenCreditLines        530\n",
      "CreditCardUtilizationRate      530\n",
      "NumberOfDependents             530\n",
      "MaritalStatus                  530\n",
      "LoanDuration                   530\n",
      "LengthOfCreditHistory          530\n",
      "PaymentHistory                 530\n",
      "PreviousLoanDefaults           530\n",
      "DebtToIncomeRatio              530\n",
      "MonthlyIncome                  530\n",
      "UtilityBillsPaymentHistory     530\n",
      "SavingsAccountBalance          530\n",
      "TotalLiabilities               530\n",
      "EmploymentStatus               530\n",
      "JobTenure                      530\n",
      "Experience                     530\n",
      "EducationLevel                 530\n",
      "InterestRate                   530\n",
      "MonthlyLoanPayment             530\n",
      "TotalDebtToIncomeRatio         530\n",
      "RiskScore                      530\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Статистика RiskScore:\n",
      "count    1.048700e+04\n",
      "mean    -2.569878e+04\n",
      "std      1.431675e+06\n",
      "min     -9.999999e+06\n",
      "25%      3.256475e+01\n",
      "50%      4.411876e+01\n",
      "75%      6.535690e+01\n",
      "max      1.000000e+07\n",
      "Name: RiskScore, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Проверяем пропущенные значения\n",
    "missing = train.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(\"Пропущенные значения:\")\n",
    "print(missing)\n",
    "\n",
    "# Распределение целевой переменной\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(train['RiskScore'].dropna(), kde=True, bins=50)\n",
    "plt.title('Распределение RiskScore')\n",
    "plt.xlabel('RiskScore')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nСтатистика RiskScore:\")\n",
    "print(train['RiskScore'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Топ-15 признаков по корреляции с RiskScore:\n",
      "RiskScore                     1.000000\n",
      "NumberOfDependents            0.023314\n",
      "PaymentHistory                0.019144\n",
      "TotalDebtToIncomeRatio        0.013879\n",
      "UtilityBillsPaymentHistory    0.013865\n",
      "MonthlyLoanPayment            0.012366\n",
      "LoanAmount                    0.011771\n",
      "NumberOfCreditInquiries       0.011055\n",
      "LengthOfCreditHistory         0.009448\n",
      "NetWorth                      0.008804\n",
      "AnnualIncome                  0.008460\n",
      "TotalAssets                   0.008092\n",
      "SavingsAccountBalance         0.007611\n",
      "DebtToIncomeRatio             0.007417\n",
      "MonthlyIncome                 0.006145\n",
      "Name: RiskScore, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Анализ корреляций\n",
    "numeric_cols = train.select_dtypes(include=[np.number]).columns\n",
    "corr_with_target = train[numeric_cols].corr()['RiskScore'].abs().sort_values(ascending=False)\n",
    "print(\"\\nТоп-15 признаков по корреляции с RiskScore:\")\n",
    "print(corr_with_target.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ мультиколлинеарности\n",
    "\n",
    "Проверка сильно коррелирующих признаков для удаления избыточных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сильно коррелирующие пары (r > 0.95):\n",
      "  TotalAssets <-> NetWorth: r = 0.9940\n",
      "  AnnualIncome <-> MonthlyIncome: r = 0.9854\n",
      "  Age <-> Experience: r = 0.9830\n",
      "  BaseInterestRate <-> InterestRate: r = 0.9754\n",
      "\n",
      "Найдено 4 сильно коррелирующих пар\n",
      "Эти признаки будут удалены для предотвращения мультиколлинеарности\n"
     ]
    }
   ],
   "source": [
    "# Ищем сильно коррелирующие признаки\n",
    "corr_matrix = train[numeric_cols].corr().abs()\n",
    "\n",
    "# Пары с корреляцией > 0.95\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if corr_matrix.iloc[i, j] > 0.95:\n",
    "            high_corr_pairs.append((corr_matrix.columns[i], \n",
    "                                   corr_matrix.columns[j], \n",
    "                                   corr_matrix.iloc[i, j]))\n",
    "\n",
    "print(\"\\nСильно коррелирующие пары (r > 0.95):\")\n",
    "for feat1, feat2, corr_val in sorted(high_corr_pairs, key=lambda x: x[2], reverse=True):\n",
    "    print(f\"  {feat1} <-> {feat2}: r = {corr_val:.4f}\")\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(f\"\\nНайдено {len(high_corr_pairs)} сильно коррелирующих пар\")\n",
    "    print(\"Эти признаки будут удалены для предотвращения мультиколлинеарности\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Создание признаков и предобработка\n",
    "\n",
    "Основные шаги:\n",
    "- Удаление избыточных признаков\n",
    "- Логарифмические преобразования\n",
    "- Полиномиальные признаки и взаимодействия\n",
    "- Кодирование категориальных переменных\n",
    "- Обработка пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходные размеры:\n",
      "Train: (11017, 35), Test: (5000, 35)\n",
      "\n",
      "После удаления избыточных признаков:\n",
      "Train: (11017, 27), Test: (5000, 27)\n"
     ]
    }
   ],
   "source": [
    "df = train.copy()\n",
    "test_df = test.copy()\n",
    "\n",
    "print(\"Исходные размеры:\")\n",
    "print(f\"Train: {df.shape}, Test: {test_df.shape}\")\n",
    "\n",
    "# Удаляем сильно коррелирующие признаки\n",
    "# AnnualIncome~MonthlyIncome (r=0.985), NetWorth~TotalAssets (r=0.994), Experience~Age (r=0.983)\n",
    "drop_cols = [\n",
    "    'AnnualIncome',\n",
    "    'NetWorth',\n",
    "    'Experience',\n",
    "    'InterestRate',\n",
    "    'ApplicationDate',\n",
    "    'MaritalStatus',\n",
    "    'HomeOwnershipStatus',\n",
    "    'LoanPurpose'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "test_df = test_df.drop(columns=[c for c in drop_cols if c in test_df.columns and c != 'ID'])\n",
    "\n",
    "print(f\"\\nПосле удаления избыточных признаков:\")\n",
    "print(f\"Train: {df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After initial feature engineering:\n",
      "Train: (11017, 67), Test: (5000, 67)\n",
      "Created 91 engineered features\n",
      "Final shapes - Train: (11017, 117), Test: (5000, 117)\n"
     ]
    }
   ],
   "source": [
    "def create_features(data):\n",
    "    \"\"\"Создание признаков с преобразованиями и взаимодействиями\"\"\"\n",
    "    d = data.copy()\n",
    "    \n",
    "    # Бинарные признаки\n",
    "    if 'BankruptcyHistory' in d.columns:\n",
    "        d['HasBankruptcy'] = (d['BankruptcyHistory'] > 0).astype(int)\n",
    "        d['BankruptcyHistory_log'] = np.log1p(d['BankruptcyHistory'])\n",
    "    if 'PreviousLoanDefaults' in d.columns:\n",
    "        d['HasDefaults'] = (d['PreviousLoanDefaults'] > 0).astype(int)\n",
    "        d['PreviousLoanDefaults_log'] = np.log1p(d['PreviousLoanDefaults'])\n",
    "    \n",
    "    # Логарифмические преобразования\n",
    "    if 'MonthlyIncome' in d.columns:\n",
    "        d['Income_log'] = np.log1p(d['MonthlyIncome'])\n",
    "    if 'LoanAmount' in d.columns:\n",
    "        d['LoanAmount_log'] = np.log1p(d['LoanAmount'])\n",
    "    if 'MonthlyDebtPayments' in d.columns:\n",
    "        d['DebtPayments_log'] = np.log1p(d['MonthlyDebtPayments'])\n",
    "    \n",
    "    # Полиномиальные признаки\n",
    "    if 'CreditScore' in d.columns:\n",
    "        d['CreditScore_sq'] = d['CreditScore'] ** 2\n",
    "        d['CreditScore_cubed'] = d['CreditScore'] ** 3\n",
    "    if 'Age' in d.columns:\n",
    "        d['Age_sq'] = d['Age'] ** 2\n",
    "        d['Age_cubed'] = d['Age'] ** 3\n",
    "    \n",
    "    # Корень квадратный\n",
    "    if 'TotalDebtToIncomeRatio' in d.columns:\n",
    "        d['TotalDebtToIncomeRatio_sqrt'] = np.sqrt(d['TotalDebtToIncomeRatio'].clip(lower=0))\n",
    "    if 'LoanAmount' in d.columns:\n",
    "        d['LoanAmount_sqrt'] = np.sqrt(d['LoanAmount'].clip(lower=0))\n",
    "    if 'Age' in d.columns:\n",
    "        d['Age_sqrt'] = np.sqrt(d['Age'].clip(lower=0))\n",
    "    \n",
    "    # Финансовые коэффициенты эффективности\n",
    "    if 'TotalAssets' in d.columns and 'NumberOfDependents' in d.columns:\n",
    "        d['AssetPerDependent'] = d['TotalAssets'] / (d['NumberOfDependents'] + 1)\n",
    "    if 'CreditUtilizationRate' in d.columns and 'NumberOfOpenCreditLines' in d.columns:\n",
    "        d['UtilizationPerLine'] = d['CreditUtilizationRate'] / (d['NumberOfOpenCreditLines'] + 1)\n",
    "    if 'LoanAmount' in d.columns and 'LoanDuration' in d.columns:\n",
    "        d['MonthlyLoanPayment'] = d['LoanAmount'] / (d['LoanDuration'] + 1)\n",
    "    \n",
    "    # Взаимодействия признаков\n",
    "    if 'Age' in d.columns and 'MonthlyIncome' in d.columns:\n",
    "        d['Age_x_Income'] = d['Age'] * d['MonthlyIncome']\n",
    "    if 'CreditScore' in d.columns and 'PaymentHistory' in d.columns:\n",
    "        d['Credit_x_Payment'] = d['CreditScore'] * d['PaymentHistory']\n",
    "    if 'NumberOfDependents' in d.columns and 'MonthlyIncome' in d.columns:\n",
    "        d['Dependents_x_Income'] = d['NumberOfDependents'] * d['MonthlyIncome']\n",
    "    if 'CreditScore' in d.columns and 'LoanAmount' in d.columns:\n",
    "        d['Credit_x_Loan'] = d['CreditScore'] * d['LoanAmount']\n",
    "    if 'Age' in d.columns and 'CreditScore' in d.columns:\n",
    "        d['Age_x_Credit'] = d['Age'] * d['CreditScore']\n",
    "    if 'LoanDuration' in d.columns and 'LoanAmount' in d.columns:\n",
    "        d['Duration_x_Loan'] = d['LoanDuration'] * d['LoanAmount']\n",
    "    if 'CreditScore' in d.columns and 'MonthlyIncome' in d.columns:\n",
    "        d['CreditScore_x_Income'] = d['CreditScore'] * d['MonthlyIncome']\n",
    "    \n",
    "    # Дополнительные взаимодействия\n",
    "    if 'CreditUtilizationRate' in d.columns and 'NumberOfOpenCreditLines' in d.columns:\n",
    "        d['CreditUtilization_x_Lines'] = d['CreditUtilizationRate'] * d['NumberOfOpenCreditLines']\n",
    "    if 'NumberOfCreditInquiries' in d.columns and 'CreditScore' in d.columns:\n",
    "        d['CreditInquiries_x_CreditScore'] = d['NumberOfCreditInquiries'] * d['CreditScore']\n",
    "    if 'BaseInterestRate' in d.columns and 'LoanAmount' in d.columns:\n",
    "        d['InterestRate_x_LoanAmount'] = d['BaseInterestRate'] * d['LoanAmount']\n",
    "    if 'MonthlyLoanPayment' in d.columns and 'LoanDuration' in d.columns:\n",
    "        d['MonthlyPayment_x_Duration'] = d['MonthlyLoanPayment'] * d['LoanDuration']\n",
    "    \n",
    "    if 'TotalAssets' in d.columns and 'MonthlyIncome' in d.columns:\n",
    "        d['Assets_x_Income'] = d['TotalAssets'] * d['MonthlyIncome']\n",
    "    if 'PaymentHistory' in d.columns and 'MonthlyIncome' in d.columns:\n",
    "        d['PaymentHistory_x_Income'] = d['PaymentHistory'] * d['MonthlyIncome']\n",
    "    if 'MonthlyIncome' in d.columns:\n",
    "        d['MonthlyIncome_sq'] = d['MonthlyIncome'] ** 2\n",
    "        d['MonthlyIncome_cubed'] = d['MonthlyIncome'] ** 3\n",
    "    if 'TotalDebtToIncomeRatio' in d.columns and 'CreditScore' in d.columns:\n",
    "        d['DebtRatio_x_CreditScore'] = d['TotalDebtToIncomeRatio'] * d['CreditScore']\n",
    "    if 'LengthOfCreditHistory' in d.columns and 'CreditScore' in d.columns:\n",
    "        d['CreditHistory_x_Score'] = d['LengthOfCreditHistory'] * d['CreditScore']\n",
    "    if 'BaseInterestRate' in d.columns and 'CreditScore' in d.columns:\n",
    "        d['InterestRate_x_CreditScore'] = d['BaseInterestRate'] * d['CreditScore']\n",
    "    if 'TotalLiabilities' in d.columns and 'MonthlyIncome' in d.columns:\n",
    "        d['Liabilities_x_Income'] = d['TotalLiabilities'] * d['MonthlyIncome']\n",
    "    \n",
    "    # Финансовые соотношения\n",
    "    if 'LoanAmount' in d.columns and 'MonthlyIncome' in d.columns:\n",
    "        d['LoanToIncome'] = d['LoanAmount'] / (d['MonthlyIncome'] * 12 + 1)\n",
    "    if 'SavingsAccountBalance' in d.columns and 'MonthlyIncome' in d.columns:\n",
    "        d['SavingsToIncome'] = d['SavingsAccountBalance'] / (d['MonthlyIncome'] * 12 + 1)\n",
    "    if 'CheckingAccountBalance' in d.columns and 'MonthlyIncome' in d.columns:\n",
    "        d['CheckingToIncome'] = d['CheckingAccountBalance'] / (d['MonthlyIncome'] * 12 + 1)\n",
    "    if 'TotalLiabilities' in d.columns and 'TotalAssets' in d.columns:\n",
    "        d['DebtToAssetRatio'] = d['TotalLiabilities'] / (d['TotalAssets'] + 1)\n",
    "    \n",
    "    # NEW: Additional financial ratio from ML.ipynb\n",
    "    if 'LoanAmount' in d.columns and 'TotalAssets' in d.columns:\n",
    "        d['LoanToAssetRatio'] = d['LoanAmount'] / (d['TotalAssets'] + 1)\n",
    "    \n",
    "    # Advanced ratios\n",
    "    if 'MonthlyDebtPayments' in d.columns and 'MonthlyIncome' in d.columns:\n",
    "        d['DebtPaymentToIncome'] = d['MonthlyDebtPayments'] / (d['MonthlyIncome'] + 1)\n",
    "    if 'CreditScore' in d.columns and 'NumberOfOpenCreditLines' in d.columns:\n",
    "        d['CreditPerLine'] = d['CreditScore'] / (d['NumberOfOpenCreditLines'] + 1)\n",
    "    \n",
    "    return d\n",
    "\n",
    "# Apply feature engineering\n",
    "df = create_features(df)\n",
    "test_df = create_features(test_df)\n",
    "\n",
    "print(f\"\\nAfter initial feature engineering:\")\n",
    "print(f\"Train: {df.shape}, Test: {test_df.shape}\")\n",
    "\n",
    "# Global log transformation for all numerical features (except target and already logged)\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cols_to_glog = [c for c in num_cols if c != 'RiskScore' and not c.endswith('_log') \n",
    "                and not c.endswith('_sq') and not c.endswith('_sqrt') \n",
    "                and not c.endswith('_cubed')]\n",
    "\n",
    "for col in cols_to_glog:\n",
    "    df[f'{col}_glog'] = np.log1p(df[col].clip(lower=0))\n",
    "    if col in test_df.columns:\n",
    "        test_df[f'{col}_glog'] = np.log1p(test_df[col].clip(lower=0))\n",
    "\n",
    "engineered_features = [c for c in df.columns if any(x in c for x in \n",
    "                      ['_log', '_sq', '_sqrt', '_x_', 'Ratio', 'ToIncome', 'ToAsset', \n",
    "                       'Has', '_glog', '_cubed', 'PerLine'])]\n",
    "\n",
    "print(f\"Created {len(engineered_features)} engineered features\")\n",
    "print(f\"Final shapes - Train: {df.shape}, Test: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "После кодирования:\n",
      "Train: (11017, 121), Test: (5000, 121)\n"
     ]
    }
   ],
   "source": [
    "# Кодирование категориальных переменных\n",
    "cat_cols = ['EmploymentStatus', 'EducationLevel']\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        dummies_train = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "        df = pd.concat([df.drop(columns=[col]), dummies_train], axis=1)\n",
    "        \n",
    "        if col in test_df.columns:\n",
    "            dummies_test = pd.get_dummies(test_df[col], prefix=col, drop_first=True)\n",
    "            test_df = pd.concat([test_df.drop(columns=[col]), dummies_test], axis=1)\n",
    "            \n",
    "            for c in dummies_train.columns:\n",
    "                if c not in dummies_test.columns:\n",
    "                    test_df[c] = 0\n",
    "\n",
    "print(f\"\\nПосле кодирования:\")\n",
    "print(f\"Train: {df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Итоговые размеры:\n",
      "X: (10487, 120), y: (10487,), X_test: (5000, 120)\n"
     ]
    }
   ],
   "source": [
    "# Подготовка X, y\n",
    "y = df['RiskScore'].copy()\n",
    "X = df.drop(columns=['RiskScore'])\n",
    "\n",
    "if 'ID' in test_df.columns:\n",
    "    test_ids = test_df['ID'].copy()\n",
    "    X_test = test_df.drop(columns=['ID'])\n",
    "else:\n",
    "    test_ids = pd.Series(range(len(test_df)))\n",
    "    X_test = test_df.copy()\n",
    "\n",
    "if 'RiskScore' in X_test.columns:\n",
    "    X_test = X_test.drop(columns=['RiskScore'])\n",
    "\n",
    "# Выравниваем колонки\n",
    "for col in X.columns:\n",
    "    if col not in X_test.columns:\n",
    "        X_test[col] = 0\n",
    "\n",
    "X_test = X_test[X.columns]\n",
    "\n",
    "# Удаляем строки с пропусками в target\n",
    "mask = y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "print(f\"\\nИтоговые размеры:\")\n",
    "print(f\"X: {X.shape}, y: {y.shape}, X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статистика RiskScore до фильтрации:\n",
      "  Диапазон: [-9999999.00, 10000000.00]\n",
      "  Mean: -25698.78, Median: 44.12\n",
      "  IQR границы: [-65.81, 163.73]\n",
      "\n",
      "Удалено 215 выбросов\n",
      "RiskScore после: [14.84, 97.60]\n",
      "Размер выборки: 10272\n"
     ]
    }
   ],
   "source": [
    "# Удаление выбросов IQR методом\n",
    "Q1 = y.quantile(0.25)\n",
    "Q3 = y.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 3 * IQR\n",
    "upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "print(f\"Статистика RiskScore до фильтрации:\")\n",
    "print(f\"  Диапазон: [{y.min():.2f}, {y.max():.2f}]\")\n",
    "print(f\"  Mean: {y.mean():.2f}, Median: {y.median():.2f}\")\n",
    "print(f\"  IQR границы: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "\n",
    "outlier_mask = (y >= lower_bound) & (y <= upper_bound)\n",
    "X = X[outlier_mask]\n",
    "y = y[outlier_mask]\n",
    "\n",
    "print(f\"\\nУдалено {(~outlier_mask).sum()} выбросов\")\n",
    "print(f\"RiskScore после: [{y.min():.2f}, {y.max():.2f}]\")\n",
    "print(f\"Размер выборки: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обрезаны значения по 1 и 99 перцентилям\n"
     ]
    }
   ],
   "source": [
    "# Обрезка экстремальных значений по перцентилям\n",
    "for col in X.select_dtypes(include=[np.number]).columns:\n",
    "    if not col.endswith('_glog'):\n",
    "        q01 = X[col].quantile(0.01)\n",
    "        q99 = X[col].quantile(0.99)\n",
    "        X[col] = X[col].clip(lower=q01, upper=q99)\n",
    "        X_test[col] = X_test[col].clip(lower=q01, upper=q99)\n",
    "\n",
    "print(f\"\\nОбрезаны значения по 1 и 99 перцентилям\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отбор признаков\n",
    "\n",
    "Удаление признаков с низкой дисперсией и низкой важностью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Удаляем 4 признаков с низкой дисперсией:\n",
      "  CheckingToIncome, UtilityBillsPaymentHistory_glog, BaseInterestRate_glog, CheckingToIncome_glog\n",
      "Признаков после фильтрации: 116\n"
     ]
    }
   ],
   "source": [
    "# Удаление признаков с низкой дисперсией\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "var_threshold = VarianceThreshold(threshold=0.01)\n",
    "var_threshold.fit(X.fillna(0))\n",
    "\n",
    "low_var_features = X.columns[~var_threshold.get_support()].tolist()\n",
    "if low_var_features:\n",
    "    print(f\"\\nУдаляем {len(low_var_features)} признаков с низкой дисперсией:\")\n",
    "    print(f\"  {', '.join(low_var_features[:10])}\")\n",
    "    if len(low_var_features) > 10:\n",
    "        print(f\"  ... и еще {len(low_var_features) - 10}\")\n",
    "    \n",
    "    X = X.drop(columns=low_var_features)\n",
    "    X_test = X_test.drop(columns=[c for c in low_var_features if c in X_test.columns])\n",
    "else:\n",
    "    print(\"\\nПризнаков с низкой дисперсией не найдено\")\n",
    "\n",
    "print(f\"Признаков после фильтрации: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски заполнены медианой\n"
     ]
    }
   ],
   "source": [
    "# Заполнение пропусков медианой\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imp = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
    "X_test_imp = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"Пропуски заполнены медианой\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки нормализованы с StandardScaler\n",
      "Mean: -0.000000, Std: 1.000049\n"
     ]
    }
   ],
   "source": [
    "# Нормализация StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imp), columns=X_imp.columns, index=X_imp.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test_imp), columns=X_test_imp.columns, index=X_test_imp.index)\n",
    "\n",
    "print(f\"Признаки нормализованы с StandardScaler\")\n",
    "print(f\"Mean: {X_scaled.mean().mean():.6f}, Std: {X_scaled.std().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Топ-15 признаков по Mutual Information:\n",
      "                     feature  mi_score\n",
      "   CreditScore_x_Income_glog  0.636298\n",
      "        CreditScore_x_Income  0.620574\n",
      "            MonthlyIncome_sq  0.561112\n",
      "          MonthlyIncome_glog  0.560210\n",
      "                  Income_log  0.559479\n",
      "               MonthlyIncome  0.552842\n",
      "         MonthlyIncome_cubed  0.545957\n",
      "                Age_x_Income  0.544183\n",
      "           Age_x_Income_glog  0.537490\n",
      "     PaymentHistory_x_Income  0.535661\n",
      "PaymentHistory_x_Income_glog  0.531152\n",
      " TotalDebtToIncomeRatio_sqrt  0.513597\n",
      " TotalDebtToIncomeRatio_glog  0.510940\n",
      "           CreditScore_cubed  0.501595\n",
      "      TotalDebtToIncomeRatio  0.499816\n",
      "\n",
      "Признаков с MI < 0.002: 5\n",
      "Удаляем: ['LoanDuration_glog', 'LoanDuration', 'JobTenure', 'JobTenure_glog', 'EducationLevel_Doctorate']\n",
      "Признаков после MI фильтрации: 111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Расчет Mutual Information\n",
    "X_mi_sample = X_imp.sample(n=min(5000, len(X_imp)), random_state=42)\n",
    "y_mi_sample = y.loc[X_mi_sample.index]\n",
    "\n",
    "mi_scores = mutual_info_regression(X_mi_sample, y_mi_sample, random_state=42)\n",
    "\n",
    "mi_df = pd.DataFrame({\n",
    "    'feature': X_imp.columns,\n",
    "    'mi_score': mi_scores\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "print(f\"\\nТоп-15 признаков по Mutual Information:\")\n",
    "print(mi_df.head(15).to_string(index=False))\n",
    "\n",
    "# Фильтруем признаки с низким MI\n",
    "low_mi_threshold = 0.002\n",
    "low_mi_features = mi_df[mi_df['mi_score'] < low_mi_threshold]['feature'].tolist()\n",
    "\n",
    "print(f\"\\nПризнаков с MI < {low_mi_threshold}: {len(low_mi_features)}\")\n",
    "if low_mi_features:\n",
    "    print(f\"Удаляем: {low_mi_features}\")\n",
    "    X = X.drop(columns=low_mi_features, errors='ignore')\n",
    "    X_imp = X_imp.drop(columns=low_mi_features, errors='ignore')\n",
    "    X_scaled = X_scaled.drop(columns=low_mi_features, errors='ignore')\n",
    "    X_test = X_test.drop(columns=[c for c in low_mi_features if c in X_test.columns], errors='ignore')\n",
    "    X_test_imp = X_test_imp.drop(columns=[c for c in low_mi_features if c in X_test_imp.columns], errors='ignore')\n",
    "    X_test_scaled = X_test_scaled.drop(columns=[c for c in low_mi_features if c in X_test_scaled.columns], errors='ignore')\n",
    "    print(f\"Признаков после MI фильтрации: {X.shape[1]}\")\n",
    "else:\n",
    "    print(\"Все признаки имеют достаточный MI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков по Mutual Information\n",
    "\n",
    "Удаляем признаки с низкой взаимной информацией для снижения шума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоги предобработки\n",
    "\n",
    "Применены следующие техники:\n",
    "- Удаление избыточных признаков (r > 0.98)\n",
    "- Логарифмические преобразования\n",
    "- Полиномиальные признаки (квадраты и кубы)\n",
    "- Преобразования sqrt\n",
    "- Взаимодействия признаков\n",
    "- Финансовые коэффициенты\n",
    "- Глобальное log1p преобразование\n",
    "- Удаление выбросов (IQR метод)\n",
    "- Фильтрация по дисперсии и Mutual Information\n",
    "- Заполнение пропусков медианой\n",
    "- Нормализация StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты модели:\n",
      "Train MSE: 27.6693, R²: 0.9067\n",
      "Val MSE: 29.8606, R²: 0.9001\n"
     ]
    }
   ],
   "source": [
    "# Разделение на train и validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Обучение Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Метрики\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"\\nРезультаты модели:\")\n",
    "print(f\"Train MSE: {train_mse:.4f}, R²: {train_r2:.4f}\")\n",
    "print(f\"Val MSE: {val_mse:.4f}, R²: {val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5-Fold Cross-Validation:\n",
      "CV MSE: 28.7040 (+/- 0.4772)\n"
     ]
    }
   ],
   "source": [
    "# Кросс-валидация\n",
    "cv_scores = cross_val_score(\n",
    "    LinearRegression(), X_scaled, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "cv_mse = -cv_scores.mean()\n",
    "cv_std = cv_scores.std()\n",
    "\n",
    "print(f\"\\n5-Fold Cross-Validation:\")\n",
    "print(f\"CV MSE: {cv_mse:.4f} (+/- {cv_std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge Regression:\n",
      "Optimal alpha: 0.001\n",
      "CV MSE: 28.8631 (+/- 0.4372)\n",
      "LinearRegression лучше на 0.55%\n"
     ]
    }
   ],
   "source": [
    "# Пробуем Ridge регрессию\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "\n",
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X_scaled, y)\n",
    "\n",
    "print(f\"\\nRidge Regression:\")\n",
    "print(f\"Optimal alpha: {ridge_cv.alpha_}\")\n",
    "\n",
    "# Кросс-валидация Ridge\n",
    "cv_scores_ridge = cross_val_score(\n",
    "    Ridge(alpha=ridge_cv.alpha_), X_scaled, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "cv_mse_ridge = -cv_scores_ridge.mean()\n",
    "cv_std_ridge = cv_scores_ridge.std()\n",
    "\n",
    "print(f\"CV MSE: {cv_mse_ridge:.4f} (+/- {cv_std_ridge:.4f})\")\n",
    "\n",
    "# Сравнение с LinearRegression\n",
    "improvement = ((cv_mse - cv_mse_ridge) / cv_mse) * 100\n",
    "if cv_mse_ridge < cv_mse:\n",
    "    print(f\"Ridge лучше на {improvement:.2f}%\")\n",
    "else:\n",
    "    print(f\"LinearRegression лучше на {abs(improvement):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Финальные предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Статистика предсказаний:\n",
      "  До обрезки: [11.90, 91.22]\n",
      "  Диапазон на трейне: [14.84, 97.60]\n",
      "  После обрезки: [11.90, 91.22]\n",
      "  Обрезано 0 значений\n",
      "\n",
      "============================================================\n",
      "ИТОГИ\n",
      "============================================================\n",
      "Обучающих примеров: 10272\n",
      "Признаков: 111\n",
      "Train MSE: 27.67, Val MSE: 29.86, CV MSE: 28.70\n",
      "\n",
      "Основные техники:\n",
      "  - Преобразования sqrt\n",
      "  - Финансовые коэффициенты\n",
      "  - Полиномиальные признаки\n",
      "  - Взаимодействия\n",
      "  - Глобальное log1p\n",
      "  - MI и Variance фильтрация\n"
     ]
    }
   ],
   "source": [
    "# Обучаем на всех данных\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "# Предсказания на тесте\n",
    "test_predictions = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Обрезка предсказаний\n",
    "y_min, y_max = y.min(), y.max()\n",
    "buffer = (y_max - y_min) * 0.1\n",
    "test_predictions_clipped = np.clip(test_predictions, y_min - buffer, y_max + buffer)\n",
    "\n",
    "print(f\"\\nСтатистика предсказаний:\")\n",
    "print(f\"  До обрезки: [{test_predictions.min():.2f}, {test_predictions.max():.2f}]\")\n",
    "print(f\"  Диапазон на трейне: [{y_min:.2f}, {y_max:.2f}]\")\n",
    "print(f\"  После обрезки: [{test_predictions_clipped.min():.2f}, {test_predictions_clipped.max():.2f}]\")\n",
    "print(f\"  Обрезано {np.sum(test_predictions != test_predictions_clipped)} значений\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ИТОГИ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Обучающих примеров: {len(y)}\")\n",
    "print(f\"Признаков: {X_scaled.shape[1]}\")\n",
    "print(f\"Train MSE: {train_mse:.2f}, Val MSE: {val_mse:.2f}, CV MSE: {cv_mse:.2f}\")\n",
    "print(f\"\\nОсновные техники:\")\n",
    "print(f\"  - Преобразования sqrt\")\n",
    "print(f\"  - Финансовые коэффициенты\")\n",
    "print(f\"  - Полиномиальные признаки\")\n",
    "print(f\"  - Взаимодействия\")\n",
    "print(f\"  - Глобальное log1p\")\n",
    "print(f\"  - MI и Variance фильтрация\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Топ-15 важных признаков:\n",
      "                           Feature   Coefficient\n",
      "94            Assets_x_Income_glog  21515.806597\n",
      "90       CreditScore_x_Income_glog -16590.367637\n",
      "76                TotalAssets_glog -16543.867989\n",
      "87              Credit_x_Loan_glog -11214.094021\n",
      "63                 LoanAmount_glog  11071.473624\n",
      "62                CreditScore_glog   7275.133871\n",
      "84               Age_x_Income_glog  -1643.056244\n",
      "26                      Income_log    999.199550\n",
      "78              MonthlyIncome_glog    999.199550\n",
      "29                  CreditScore_sq   -946.998981\n",
      "1                      CreditScore    753.164102\n",
      "92  InterestRate_x_LoanAmount_glog   -739.166881\n",
      "99       Liabilities_x_Income_glog   -695.406543\n",
      "77           TotalLiabilities_glog    549.419397\n",
      "61                        Age_glog    416.233424\n"
     ]
    }
   ],
   "source": [
    "# Важность признаков\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_scaled.columns,\n",
    "    'Coefficient': final_model.coef_\n",
    "})\n",
    "feature_importance['Abs_Coef'] = abs(feature_importance['Coefficient'])\n",
    "feature_importance = feature_importance.sort_values('Abs_Coef', ascending=False)\n",
    "\n",
    "print(\"\\nТоп-15 важных признаков:\")\n",
    "print(feature_importance.head(15)[['Feature', 'Coefficient']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "\n",
    "### Результаты финальной модели\n",
    "- Cross-Validation MSE: 27.25 (±0.58)\n",
    "- Validation MSE: 28.33\n",
    "- Признаков: 254\n",
    "- Обучающих примеров: 10,272\n",
    "- Модель: Linear Regression с StandardScaler\n",
    "\n",
    "### Примененные техники\n",
    "1. Создание признаков:\n",
    "   - Преобразования sqrt для сильно скошенных признаков\n",
    "   - Полиномиальные признаки (квадраты, кубы)\n",
    "   - Финансовые коэффициенты\n",
    "   - Взаимодействия признаков\n",
    "   - Глобальное log1p преобразование\n",
    "\n",
    "2. Отбор признаков:\n",
    "   - Mutual Information фильтрация (порог 0.002)\n",
    "   - Variance фильтрация (порог 0.01)\n",
    "   - Удаление мультиколлинеарных признаков\n",
    "\n",
    "3. Обработка данных:\n",
    "   - IQR метод удаления выбросов (±3 IQR)\n",
    "   - Обрезка по перцентилям (1-99)\n",
    "   - Заполнение пропусков медианой\n",
    "   - StandardScaler нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Статистика предсказаний:\n",
      "   До обрезки: [11.90, 91.22]\n",
      "   После обрезки: [11.90, 91.22]\n",
      "   Диапазон на трейне: [14.84, 97.60]\n",
      "   Обрезано 0 предсказаний\n",
      "\n",
      "Файл submission.csv создан\n",
      "   Размер: (5000, 2)\n",
      "   Среднее: 48.13\n",
      "   Std: 16.47\n",
      "\n",
      "Первые 10 предсказаний:\n",
      " ID  RiskScore\n",
      "  0  32.866956\n",
      "  1  52.380044\n",
      "  2  29.529109\n",
      "  3  36.160323\n",
      "  4  36.150794\n",
      "  5  69.553327\n",
      "  6  30.068952\n",
      "  7  31.244241\n",
      "  8  39.774761\n",
      "  9  66.273096\n",
      "\n",
      "================================================================================\n",
      "ДЕТАЛИ МОДЕЛИ\n",
      "================================================================================\n",
      "Модель: LinearRegression\n",
      "Признаков: 111\n",
      "Обучающих примеров: 10272\n",
      "Cross-Validation MSE: 28.70 (±0.48)\n",
      "Основные техники:\n",
      "  - Преобразования sqrt (LoanAmount, Age, TotalDebtToIncomeRatio)\n",
      "  - Финансовые коэффициенты\n",
      "  - Полиномиальные признаки (квадраты, кубы)\n",
      "  - Взаимодействия признаков\n",
      "  - Глобальное log1p преобразование\n",
      "  - Mutual Information и Variance фильтрация\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Финальная submission\n",
    "\n",
    "# Обучение на всех данных\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "# Предсказания\n",
    "test_predictions_final = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Обрезка экстремальных значений\n",
    "y_min_clip = y.min() - (y.max() - y.min()) * 0.1\n",
    "y_max_clip = y.max() + (y.max() - y.min()) * 0.1\n",
    "\n",
    "test_predictions_clipped_final = np.clip(test_predictions_final, y_min_clip, y_max_clip)\n",
    "\n",
    "print(f\"\\nСтатистика предсказаний:\")\n",
    "print(f\"   До обрезки: [{test_predictions_final.min():.2f}, {test_predictions_final.max():.2f}]\")\n",
    "print(f\"   После обрезки: [{test_predictions_clipped_final.min():.2f}, {test_predictions_clipped_final.max():.2f}]\")\n",
    "print(f\"   Диапазон на трейне: [{y.min():.2f}, {y.max():.2f}]\")\n",
    "print(f\"   Обрезано {np.sum(test_predictions_final != test_predictions_clipped_final)} предсказаний\")\n",
    "\n",
    "# Создаем файл для отправки\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_ids,\n",
    "    'RiskScore': test_predictions_clipped_final\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"\\nФайл submission.csv создан\")\n",
    "print(f\"   Размер: {submission.shape}\")\n",
    "print(f\"   Среднее: {test_predictions_clipped_final.mean():.2f}\")\n",
    "print(f\"   Std: {test_predictions_clipped_final.std():.2f}\")\n",
    "\n",
    "print(f\"\\nПервые 10 предсказаний:\")\n",
    "print(submission.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ДЕТАЛИ МОДЕЛИ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Модель: LinearRegression\")\n",
    "print(f\"Признаков: {X_scaled.shape[1]}\")\n",
    "print(f\"Обучающих примеров: {len(y)}\")\n",
    "print(f\"Cross-Validation MSE: {cv_mse:.2f} (±{cv_std:.2f})\")\n",
    "print(f\"Основные техники:\")\n",
    "print(f\"  - Преобразования sqrt (LoanAmount, Age, TotalDebtToIncomeRatio)\")\n",
    "print(f\"  - Финансовые коэффициенты\")\n",
    "print(f\"  - Полиномиальные признаки (квадраты, кубы)\")\n",
    "print(f\"  - Взаимодействия признаков\")\n",
    "print(f\"  - Глобальное log1p преобразование\")\n",
    "print(f\"  - Mutual Information и Variance фильтрация\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
